# -*- coding: utf-8 -*-
"""Vertebrates Conditional GAN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Trc7jFLNLVZ6lcmsNrzDSbYhjORrUb2D
"""

!pip install -q git+https://github.com/tensorflow/docs

"""## Imports"""

from tensorflow import keras
from tensorflow.keras import layers

import tensorflow as tf
import numpy as np

from PIL import Image as im
import matplotlib.pyplot as plt

import os
import cv2 as cv
import numpy as np
from urllib.parse import urljoin
from google.colab.patches import cv2_imshow

BASE_PATH = "/content/drive/MyDrive/vertebrates_data/"
PROC_TRAIN = urljoin(BASE_PATH, "processed/train/")

"""## mount to drive"""

from google.colab import drive
drive.mount("/content/drive")

"""## Prepare the Data"""

def img_to_arr(path):
  # image as np array
  image = cv.imread(path, cv.IMREAD_GRAYSCALE)
  image = cv.resize(image, (240, 240), interpolation = cv.INTER_LINEAR)
  np_img = np.array(image)
  return np_img


class_names = ['L1 SUPERIOR/', 'L2 SUPERIOR/', 'L3 SUPERIOR/', 'L4 SUPERIOR/', 'L5 SUPERIOR/']

vert_train_x = []
vert_train_y = []

for i, c in enumerate(class_names):
  path = urljoin(PROC_TRAIN, c)
  fnames = os.listdir(path)

  for filename in fnames:
    path_img = urljoin(path, filename)
    print(path_img)

    # concatenate all images to one array
    vert_train_x.append(img_to_arr(path_img))
    # concatenate all labels to one array
    vert_train_y.append(i+1)

    cv.waitKey(0)
    cv.destroyAllWindows()

arr_vert_train_x = np.array(vert_train_x)
arr_vert_train_y = np.array(vert_train_y)

"""## Loading the dataset and preprocessing it"""

# We'll use all the available examples from both the training and test
# sets.

all_digits = x_train = arr_vert_train_x
all_labels = y_train = arr_vert_train_y

# Constants and hyperparameters
batch_size = 16 # 32
num_channels = 1 # 1 = grayscale; 3 = RGB
num_classes = 10
image_size = x_train.shape[1]
latent_dim = 100
buffer_size = 256

# all_digits = np.concatenate([x_train, x_test])
# all_labels = np.concatenate([y_train, y_test])

# Scale the pixel values to [0, 1] range, add a channel dimension to
# the images, and one-hot encode the labels.
all_digits = all_digits.astype("float32") / 255.0

all_digits = np.reshape(all_digits, (-1, image_size, image_size, num_channels))
print("all_digits {}".format(all_digits.shape))

all_labels = keras.utils.to_categorical(all_labels, 10)
print("all_labels {}".format(all_labels.shape))

# Create tf.data.Dataset.
dataset = tf.data.Dataset.from_tensor_slices((all_digits, all_labels))
dataset = dataset.shuffle(buffer_size=buffer_size).batch(batch_size)

print(f"Shape of training images: {all_digits.shape}")
print(f"Shape of training labels: {all_labels.shape}")

plt.imshow(x_train[0], cmap='gray')

"""## Calculating the number of input channel for the generator and discriminator"""

generator_in_channels = latent_dim + num_classes
discriminator_in_channels = num_channels + num_classes
print(generator_in_channels, discriminator_in_channels)

"""## Creating the discriminator and generator"""

# Create the discriminator

discriminator = keras.Sequential(
    [
        keras.layers.InputLayer((image_size, image_size, discriminator_in_channels)),

        layers.Conv2D(64, kernel_size=5, strides=1, padding="same"),
        layers.ReLU(),
        layers.MaxPooling2D(strides=2),

        layers.Conv2D(64, kernel_size=5, strides=1, padding="same"),
        layers.ReLU(),
        layers.MaxPooling2D(strides=2),

        layers.Conv2D(64, kernel_size=5, strides=1, padding="same"),
        layers.ReLU(),
        layers.Dropout(0.5),
        layers.MaxPooling2D(strides=2),

        layers.Flatten(),

        layers.Dense(800),
        layers.ReLU(),
        layers.Dropout(0.5),

        layers.Dense(800),
        layers.ReLU(),
        layers.Dropout(0.5),

        layers.Dense(1),
    ],

    name="discriminator",
)

# Create the generator
generator = keras.Sequential(
    [
        keras.layers.InputLayer((generator_in_channels,)),
        layers.Dense(15 * 15 * generator_in_channels),
        layers.LeakyReLU(alpha=0.2),
        layers.Reshape((15, 15, generator_in_channels)),

        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding="same"),
        layers.LeakyReLU(alpha=0.2),
        layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding="same"),
        layers.LeakyReLU(alpha=0.2),
        layers.Conv2DTranspose(32, (4, 4), strides=(2, 2), padding="same"),
        layers.LeakyReLU(alpha=0.2),
        layers.Conv2DTranspose(1, (4, 4), strides=(2, 2), padding="same"),
    ],

    name="generator",
)

discriminator.summary()
generator.summary()

"""## Creating a `ConditionalGAN` model"""

class ConditionalGAN(keras.Model):
    def __init__(self, discriminator, generator, latent_dim):
        super().__init__()
        self.discriminator = discriminator
        self.generator = generator
        self.latent_dim = latent_dim
        self.gen_loss_tracker = keras.metrics.Mean(name="generator_loss")
        self.disc_loss_tracker = keras.metrics.Mean(name="discriminator_loss")

    @property
    def metrics(self):
        return [self.gen_loss_tracker, self.disc_loss_tracker]

    def compile(self, d_optimizer, g_optimizer, loss_fn):
        super().compile()
        self.d_optimizer = d_optimizer
        self.g_optimizer = g_optimizer
        self.loss_fn = loss_fn

    def train_step(self, data):
        # Unpack the data.
        real_images, one_hot_labels = data

        # Add dummy dimensions to the labels so that they can be concatenated with
        # the images. This is for the discriminator.
        image_one_hot_labels = one_hot_labels[:, :, None, None]
        image_one_hot_labels = tf.repeat(
            image_one_hot_labels, repeats=[image_size * image_size]
        )
        image_one_hot_labels = tf.reshape(
            image_one_hot_labels, (-1, image_size, image_size, num_classes)
        )

        # Sample random points in the latent space and concatenate the labels.
        # This is for the generator.
        batch_size = tf.shape(real_images)[0]
        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))
        random_vector_labels = tf.concat(
            [random_latent_vectors, one_hot_labels], axis=1
        )

        # Decode the noise (guided by labels) to fake images.
        generated_images = self.generator(random_vector_labels)

        # Combine them with real images. Note that we are concatenating the labels
        # with these images here.
        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)
        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)
        combined_images = tf.concat(
            [fake_image_and_labels, real_image_and_labels], axis=0
        )

        # Assemble labels discriminating real from fake images.
        labels = tf.concat(
            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0
        )

        # Train the discriminator.
        with tf.GradientTape() as tape:
            predictions = self.discriminator(combined_images)
            d_loss = self.loss_fn(labels, predictions)
        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)
        self.d_optimizer.apply_gradients(
            zip(grads, self.discriminator.trainable_weights)
        )

        # Sample random points in the latent space.
        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))
        random_vector_labels = tf.concat(
            [random_latent_vectors, one_hot_labels], axis=1
        )

        # Assemble labels that say "all real images".
        misleading_labels = tf.zeros((batch_size, 1))

        # Train the generator (note that we should *not* update the weights
        # of the discriminator)!
        with tf.GradientTape() as tape:
            fake_images = self.generator(random_vector_labels)
            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)
            predictions = self.discriminator(fake_image_and_labels)
            g_loss = self.loss_fn(misleading_labels, predictions)
        grads = tape.gradient(g_loss, self.generator.trainable_weights)
        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))

        # Monitor loss.
        self.gen_loss_tracker.update_state(g_loss)
        self.disc_loss_tracker.update_state(d_loss)
        return {
            "g_loss": self.gen_loss_tracker.result(),
            "d_loss": self.disc_loss_tracker.result(),
        }

"""## Training the Conditional GAN"""

cond_gan = ConditionalGAN(
    discriminator=discriminator, generator=generator, latent_dim=latent_dim
)
cond_gan.compile(
    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),
    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),
    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),
)

cond_gan.fit(dataset, epochs=20)

"""## Interpolating between classes with the trained generator"""

# We first extract the trained generator from our Conditional GAN.
trained_gen = cond_gan.generator

# Choose the number of intermediate images that would be generated in
# between the interpolation + 2 (start and last images).
num_interpolation = 20  # @param {type:"integer"}

# Sample noise for the interpolation.
interpolation_noise = tf.random.normal(shape=(1, latent_dim))
interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)
interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))


def interpolate_class(first_number, second_number):
    # Convert the start and end labels to one-hot encoded vectors.
    first_label = keras.utils.to_categorical([first_number], num_classes)
    second_label = keras.utils.to_categorical([second_number], num_classes)
    first_label = tf.cast(first_label, tf.float32)
    second_label = tf.cast(second_label, tf.float32)

    # Calculate the interpolation vector between the two labels.
    percent_second_label = tf.linspace(0, 1, num_interpolation)[:, None]
    percent_second_label = tf.cast(percent_second_label, tf.float32)
    interpolation_labels = (
        first_label * (1 - percent_second_label) + second_label * percent_second_label
    )

    # Combine the noise and the labels and run inference with the generator.
    noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)
    fake = trained_gen.predict(noise_and_labels)
    return fake

"""Here, we first sample noise from a normal distribution and then we repeat that for
`num_interpolation` times and reshape the result accordingly.
We then distribute it uniformly for `num_interpolation`
with the label identities being present in some proportion.
"""

for i in range(1, 6):
  # generate images for each class
  fake_images = interpolate_class(i, i)
  fake_images *= 255.0
  converted_images = fake_images.astype(np.uint8)

  for j, con_im in enumerate(converted_images):
    plt.figure(frameon=False)
    plt.imshow(con_im, cmap='gray')
    cv.imwrite('/content/drive/MyDrive/vertebrates_data/GAN/L{} SUPERIOR/GAN_{}.jpg'.format(i, j), con_im)
